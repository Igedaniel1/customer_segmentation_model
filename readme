# ğŸ“Š Customer Default Prediction Project

## ğŸ¯ Objective

Predict whether a customer will default using features like Age, Income, Debt, Years Employed, etc.  
This is a binary classification task with class imbalance (fewer defaulters than non-defaulters).



## ğŸ§¹ 1. Data Cleaning

- Filled missing values in the `Defaulted` column using the **mode** to prevent training errors.



## ğŸ“ˆ 2. Exploratory Data Analysis (EDA)

- Used boxplots to visualize feature distributions by default status.
- Created a correlation heatmap. Found that `DebtIncomeRatio` had the highest correlation (~0.36) with defaulting.



## ğŸ›  3. Feature Engineering

- Applied log transformation to skewed features like income and debt.
- Engineered new features:  
  - `TotalDebt` = CardDebt + OtherDebt  
  - `IncomePerYearEmployed` = Income / YearsEmployed


## ğŸ§ª 4. Data Splitting & Imbalance Handling

- Used stratified train-test split to preserve class ratios.
- Applied SMOTE (Synthetic Minority Oversampling Technique) from `imbalanced-learn` to balance training data.
- Handled SMOTE-related errors by removing NaNs and ensuring numeric-only inputs.


## ğŸ¤– 5. Modeling

- Tried multiple models:
  - `RandomForestClassifier`: for robustness and interpretability
  - `XGBoostClassifier`: for performance on structured/tabular data
  - `HistGradientBoostingClassifier`: for speed and built-in handling of missing values


## ğŸ“Š 6. Evaluation Strategy

- Used metrics:
  - Accuracy
  - Precision
  - Recall
  - ROC AUC
- Lowered the default prediction threshold (from 0.5) to improve recall, as flagging actual defaulters is a higher priority.
- Plotted Precision-Recall and ROC curves for threshold tuning.


## ğŸ” 7. Checking Predictive Signal

- Trained the same model on random labels â†’ AUC dropped to ~0.41.
- This confirms the original model was learning a real signal.
- If AUC had remained high, it would indicate data leakage or overfitting.



## ğŸ’¡ Key Observations

- Feature correlations with the target were weak.
- Final model performance plateaued at:
  - Accuracy: ~76%
  - Precision: ~46%
  - Recall: ~65%
  - ROC AUC: ~0.80



## âœ… Conclusion

The project applied thorough preprocessing, feature engineering, class balancing, and signal validation to optimize model performance.  
However, the modelâ€™s ceiling was limited by the quality and depth of the available features.


## ğŸ“Œ Recommendation

Since many companies prioritize recall (i.e., catching actual defaulters), even at the cost of some "false positives", this model is suitable for that purpose given the current dataset.


## ğŸ”­ Next Steps

-  I'll improve data quality by collecting additional features:
  - Credit history
  - Payment timelines
  - Spending patterns
- Explore model explainability tools (e.g., SHAP).
